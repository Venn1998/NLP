{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YgPt_liDjpr"
   },
   "source": [
    "# Lorenzo Venieri \n",
    "April 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW9J3i3jhShN"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.877 · Análisis de sentimientos y textos</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencias de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicaciones</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PAC 2: Análisis de sentimientos\n",
    "\n",
    "En esta práctica revisaremos y aplicaremos los conocimientos aprendidos en las últimas semanas. Concretamente trataremos 4 temas.\n",
    "\n",
    "1. **Detección de elementos de opiniones**: Identificación de targets, aspectos y opinion words.\n",
    "2. **Detección de polaridad**: Extracción de polaridades de las opiniones.\n",
    "3. **Clasificación**: clasificación de opiniones.\n",
    "4. **Evaluación**: comparación de modelos.\n",
    "\n",
    "También repasaremos los temas genéricos de obtención y preprocesamiento de datos textuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Detection of opinion elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FP8CCrRrWuwm",
    "outputId": "dc09968c-0298-4a6a-904c-8037ec6997b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=c08e3b77d5c6470fc21afb365c3ab883fe70d26c338af81c1e3e92653ab00f45\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C06G6NWThShS",
    "outputId": "be45c860-3c2d-4cb9-a789-63a476050f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "import os\n",
    "import wget\n",
    "import gzip\n",
    "import shutil\n",
    "from nltk import pos_tag, word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miUE0wRqdlHR",
    "outputId": "f8271496-c982-4638-8166-33b404f19ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "m7o26apPBUeR",
    "outputId": "1d101d95-e52f-40eb-9e13-28bf26f3ef87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-593f128c-7dbc-419c-a3fb-f707da5ab4a2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>reviewer_nationality</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 Boulevard Saint Michel 5th arr 75005 Paris F...</td>\n",
       "      <td>120</td>\n",
       "      <td>10/25/2015</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Royal Saint Michel</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>3</td>\n",
       "      <td>1193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>[' Leisure trip ', ' Group ', ' Double Room ',...</td>\n",
       "      <td>648 day</td>\n",
       "      <td>48.852836</td>\n",
       "      <td>2.344080</td>\n",
       "      <td>l ascenseur No Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wrights Lane Kensington and Chelsea London W8 ...</td>\n",
       "      <td>1172</td>\n",
       "      <td>8/27/2015</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Holiday Inn London Kensington</td>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>5945</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Execut...</td>\n",
       "      <td>707 day</td>\n",
       "      <td>51.499981</td>\n",
       "      <td>-0.192879</td>\n",
       "      <td>Having to log in each day with a new login an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Via Tarchetti 2 Milan City Center 20121 Milan ...</td>\n",
       "      <td>436</td>\n",
       "      <td>9/18/2016</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NH Milano Touring</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>24</td>\n",
       "      <td>4568</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>319 day</td>\n",
       "      <td>45.476917</td>\n",
       "      <td>9.196665</td>\n",
       "      <td>the TV is crazy the hotel host a lot of natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avinguda Catedral 7 Ciutat Vella 08002 Barcelo...</td>\n",
       "      <td>170</td>\n",
       "      <td>2/16/2016</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Col n Hotel Barcelona</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>3</td>\n",
       "      <td>1300</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Standard Doub...</td>\n",
       "      <td>534 day</td>\n",
       "      <td>41.384961</td>\n",
       "      <td>2.175667</td>\n",
       "      <td>No complaints  Excellent location very helpfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wrights Lane Kensington and Chelsea London W8 ...</td>\n",
       "      <td>1172</td>\n",
       "      <td>6/5/2016</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Holiday Inn London Kensington</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>45</td>\n",
       "      <td>5945</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[' Leisure trip ', ' Group ', ' 2 rooms ', ' S...</td>\n",
       "      <td>424 day</td>\n",
       "      <td>51.499981</td>\n",
       "      <td>-0.192879</td>\n",
       "      <td>We booked an executive room with super king b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-593f128c-7dbc-419c-a3fb-f707da5ab4a2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-593f128c-7dbc-419c-a3fb-f707da5ab4a2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-593f128c-7dbc-419c-a3fb-f707da5ab4a2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0  3 Boulevard Saint Michel 5th arr 75005 Paris F...   \n",
       "1  Wrights Lane Kensington and Chelsea London W8 ...   \n",
       "2  Via Tarchetti 2 Milan City Center 20121 Milan ...   \n",
       "3  Avinguda Catedral 7 Ciutat Vella 08002 Barcelo...   \n",
       "4  Wrights Lane Kensington and Chelsea London W8 ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score  \\\n",
       "0                           120  10/25/2015            8.0   \n",
       "1                          1172   8/27/2015            7.8   \n",
       "2                           436   9/18/2016            8.4   \n",
       "3                           170   2/16/2016            8.9   \n",
       "4                          1172    6/5/2016            7.8   \n",
       "\n",
       "                      Hotel_Name reviewer_nationality  \\\n",
       "0             Royal Saint Michel             Lebanon    \n",
       "1  Holiday Inn London Kensington           Australia    \n",
       "2              NH Milano Touring               Qatar    \n",
       "3          Col n Hotel Barcelona             Ireland    \n",
       "4  Holiday Inn London Kensington      United Kingdom    \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                  3                     1193   \n",
       "1                                 18                     5945   \n",
       "2                                 24                     4568   \n",
       "3                                  3                     1300   \n",
       "4                                 45                     5945   \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                  0   \n",
       "1                                 56   \n",
       "2                                  6   \n",
       "3                                 37   \n",
       "4                                 12   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           1             9.6   \n",
       "1                                           2             9.6   \n",
       "2                                           2             7.1   \n",
       "3                                           3             9.2   \n",
       "4                                          12             8.8   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Group ', ' Double Room ',...           648 day   \n",
       "1  [' Leisure trip ', ' Solo traveler ', ' Execut...           707 day   \n",
       "2  [' Leisure trip ', ' Family with young childre...           319 day   \n",
       "3  [' Leisure trip ', ' Couple ', ' Standard Doub...           534 day   \n",
       "4  [' Leisure trip ', ' Group ', ' 2 rooms ', ' S...           424 day   \n",
       "\n",
       "         lat       lng                                             review  \n",
       "0  48.852836  2.344080                            l ascenseur No Positive  \n",
       "1  51.499981 -0.192879   Having to log in each day with a new login an...  \n",
       "2  45.476917  9.196665   the TV is crazy the hotel host a lot of natio...  \n",
       "3  41.384961  2.175667   No complaints  Excellent location very helpfu...  \n",
       "4  51.499981 -0.192879   We booked an executive room with super king b...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I changed the path to adapt it to my drive\n",
    "hotel_opinions_path='/content/drive/MyDrive/Colab Notebooks/NLP/PRA2/data/hotel_opinions_data.csv'\n",
    "hotel_opinions_data = pd.read_csv(hotel_opinions_path)\n",
    "hotel_opinions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OaFkUhkeiTTC",
    "outputId": "b068a49e-c86c-4f72-ddcf-ea8ac56c8e6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bd960ed9-c97b-4185-8cee-439c3c20d8b1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>reviewer_nationality</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l ascenseur No Positive</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Having to log in each day with a new login an...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the TV is crazy the hotel host a lot of natio...</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No complaints  Excellent location very helpfu...</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We booked an executive room with super king b...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd960ed9-c97b-4185-8cee-439c3c20d8b1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bd960ed9-c97b-4185-8cee-439c3c20d8b1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bd960ed9-c97b-4185-8cee-439c3c20d8b1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review reviewer_nationality  \\\n",
       "0                            l ascenseur No Positive             Lebanon    \n",
       "1   Having to log in each day with a new login an...           Australia    \n",
       "2   the TV is crazy the hotel host a lot of natio...               Qatar    \n",
       "3   No complaints  Excellent location very helpfu...             Ireland    \n",
       "4   We booked an executive room with super king b...      United Kingdom    \n",
       "\n",
       "  sentiment  \n",
       "0      good  \n",
       "1      good  \n",
       "2      good  \n",
       "3      good  \n",
       "4      good  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New label to group by good or bad reviews\n",
    "\n",
    "hotel_opinions_data[\"sentiment\"] = hotel_opinions_data[\"Reviewer_Score\"].apply(lambda x: \"good\" if x > 5 else \"bad\")\n",
    "\n",
    "# Selection of the most relevant columns\n",
    "\n",
    "hotel_opinions_data = hotel_opinions_data[[\"review\",\"reviewer_nationality\", \"sentiment\"]]\n",
    "hotel_opinions_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains reviews about hotels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oR0xDDIGhShV"
   },
   "source": [
    "- Download the model Word2Vec of the Google News dataset, with approximately 3M words:\n",
    "\n",
    "https://github.com/eyaler/word2vec-slim/blob/master/GoogleNews-vectors-negative300-SLIM.bin.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utLocHwbORDB"
   },
   "source": [
    "We will use just 500k words because of RAM limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_kKpfZ-hShV"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "google_path='/content/drive/MyDrive/Colab Notebooks/NLP/PRA2/GoogleNews-vectors-negative300-SLIM.bin.gz'\n",
    "#'GoogleNews-vectors-negative300-SLIM.bin.gz'\n",
    "wv = KeyedVectors.load_word2vec_format(google_path, binary=True, limit=500000) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNxvA-cghShW"
   },
   "source": [
    "- Convert every review in a single text in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUVVopiAhShX",
    "outputId": "96d6e20e-2b31-435a-bd48-a9753fd01fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " l ascenseur no positive  having to log in each day with a new login and password to use the wifi   \n"
     ]
    }
   ],
   "source": [
    "comment_text = \" \".join(hotel_opinions_data['review'].to_list()).lower()\n",
    "\n",
    "print(comment_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgQpT34ShShX"
   },
   "source": [
    "We obtain the phrases of the reviews. These phrases will be candidates to be targets and aspects of the opinions.\n",
    "To do so we use the attached model: model_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vE5j4yn1hShY"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import Phrases\n",
    "\n",
    "text_stream=word_tokenize(comment_text)\n",
    "\n",
    "model_phrases = Phrases.load(\"/content/drive/MyDrive/Colab Notebooks/NLP/PRA2/data/model_phrases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "gub6TzYP_gQ9",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "67c304bb-9036-4dd3-cc74-3e09b5b05b7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "ph=model_phrases[text_stream]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtDpuXgvhShZ"
   },
   "outputs": [],
   "source": [
    "def get_np(candidate):\n",
    "  np = ''\n",
    "  tokens = candidate.split('_')\n",
    "  tagged_tokens = pos_tag((tokens))\n",
    "  PoS_initial = tagged_tokens[0][1][:2]\n",
    "  PoS_final = tagged_tokens[-1][1][:2]\n",
    "  if PoS_initial == 'NN':\n",
    "    if len(tagged_tokens) > 1:\n",
    "      if PoS_final == 'NN':\n",
    "        np = candidate\n",
    "      else:\n",
    "        np = tokens[0]\n",
    "    else:\n",
    "      np = candidate\n",
    "  else:\n",
    "    if PoS_final == 'NN':\n",
    "      np = tokens[-1]\n",
    "  return np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJNBt0mphShZ"
   },
   "source": [
    "Explication:\n",
    "\n",
    "The argument (candidate) is splitted into tokens (just 1 token if the phrase is of a single word), then each token is tagged with its part of speach.\n",
    "In the command \"tagged_tokens[0][1][:2]\" the first 0 selects the tuple (token, PoS) in the list [(token,PoS)], the index 1 selects the PoS, then with [:2] we select all the characters in the PoS string.\n",
    "If its component are both nouns, the output of the function is the full input phrase. If just one of the tokens is a noun then it will be the output. If both are not nominal the function returns the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmNA_1s2hSha"
   },
   "outputs": [],
   "source": [
    "sint_nom=[get_np(candidate) for candidate in ph]\n",
    "sint_nom=[s for s in sint_nom if s!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooNGpC6jNYJt"
   },
   "outputs": [],
   "source": [
    "#store the processed comments in a file\n",
    "with open('NPs_COMMENTS.txt', 'w') as f:\n",
    "    for item in sint_nom:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXG3ggcRLS3i",
    "outputId": "c29fcf21-779b-4a6b-a271-a830d74821d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sint_nom) #before removing empty strings: >38000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEjmohmwhShb"
   },
   "outputs": [],
   "source": [
    "with open('NPs_COMMENTS.txt') as nf:\n",
    "     nps_comments = nf.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To obtain the targets of the opinions we get the 100 phrases more similar to the term \"hotel\" (for the Word2Vec embedding) that are in the opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvShKjVlhShb",
    "outputId": "42d2a197-edd0-4c32-f76c-19ef4d8f1c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Term  w2v similarity\n",
      "0       hotels        0.770973\n",
      "1        motel        0.661712\n",
      "2   restaurant        0.572378\n",
      "3          inn        0.559031\n",
      "4    apartment        0.500656\n",
      "..         ...             ...\n",
      "95    property        0.297659\n",
      "96  waterfront        0.294929\n",
      "97      dinner        0.294829\n",
      "98    building        0.294021\n",
      "99    upstairs        0.293971\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "Number of missing terms encountered: 313\n"
     ]
    }
   ],
   "source": [
    "term='hotel'\n",
    "w2v_tuples = []\n",
    "\n",
    "feature_names = list(set(nps_comments))\n",
    "missing_terms_w2v=[0]\n",
    "\n",
    "for i in range(0, len(feature_names)):\n",
    "    if feature_names[i] != term:\n",
    "      try:\n",
    "        similarity=wv.similarity(term, feature_names[i])\n",
    "        if similarity > 0:\n",
    "          w2v_tuples.append((feature_names[i], similarity))\n",
    "      except:\n",
    "        missing_terms_w2v.append(feature_names[i])\n",
    "\n",
    "w2v_sorted_tuples = sorted(w2v_tuples, key=lambda tup: tup[1], reverse=True)\n",
    "#print(w2v_sorted_tuples[:100])\n",
    "\n",
    "labels = ['Term', 'w2v similarity']\n",
    "\n",
    "df_similarity = pd.DataFrame.from_records(w2v_sorted_tuples, columns=labels)\n",
    "\n",
    "print (df_similarity[:100])\n",
    "\n",
    "print(f'Number of missing terms encountered: {len(missing_terms_w2v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also find the targets by the Wu and Palmer distance between the first synset (.n.01) of each phrase and the synset hotel.n.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lms8bgNyhShc",
    "outputId": "15893c02-5bc6-4f29-cf0c-810d51352f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adjust the dowload of NLTK, only if the dowload of 'wordnet' doesn't work properly\n",
    "\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKPaF5uFhShc",
    "outputId": "9bfd258c-4faf-499d-eafc-91032129e76e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Term  WuP similarity\n",
      "1         hostel        0.941176\n",
      "2            inn        0.941176\n",
      "3       building        0.933333\n",
      "4          motel        0.888889\n",
      "5     restaurant        0.875000\n",
      "6        theatre        0.875000\n",
      "7          house        0.875000\n",
      "8   architecture        0.875000\n",
      "9            pub        0.823529\n",
      "10          cafe        0.823529\n",
      "11      hospital        0.823529\n",
      "12        garage        0.823529\n",
      "13       balcony        0.800000\n",
      "14       stadium        0.800000\n",
      "15        bridge        0.800000\n",
      "16       shelter        0.800000\n",
      "17         tower        0.800000\n",
      "18      fountain        0.800000\n",
      "19        palace        0.777778\n",
      "20        castle        0.777778\n",
      "21         duomo        0.777778\n",
      "22       terrace        0.750000\n",
      "23        cellar        0.750000\n",
      "24          knob        0.750000\n",
      "25         works        0.750000\n",
      "26       barrier        0.750000\n",
      "27     courtyard        0.750000\n",
      "28         patio        0.750000\n",
      "29      basement        0.750000\n",
      "30          wall        0.750000\n",
      "31          room        0.750000\n",
      "32     apartment        0.750000\n",
      "33    decoration        0.714286\n",
      "34         layer        0.714286\n",
      "35      facility        0.714286\n",
      "36         block        0.714286\n",
      "37       surface        0.714286\n",
      "38        toilet        0.705882\n",
      "39        office        0.705882\n",
      "40         lobby        0.705882\n",
      "41      lavatory        0.705882\n",
      "42        closet        0.705882\n",
      "43       bedroom        0.705882\n",
      "44         foyer        0.705882\n",
      "45      bathroom        0.705882\n",
      "46          rail        0.705882\n",
      "47        window        0.705882\n",
      "48        marina        0.705882\n",
      "49         frame        0.705882\n",
      "50     penthouse        0.705882\n",
      "Number of terms missing from WordNet encountered: 1142\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wup_tuples=[]\n",
    "missing_terms=[]\n",
    "\n",
    "for term in feature_names:\n",
    "    try:\n",
    "        term=term.strip().replace(' ', '_')\n",
    "        sense_term=wn.synset(term+'.n.01')\n",
    "        wup_tuples.append((term, sense_term.wup_similarity(wn.synset('hotel.n.01'))))\n",
    "        #print(\"Wu and Palmer distance between '{}' and 'hotel(n.01)': \".format(term),\n",
    "            #sense_term.wup_similarity(wn.synset('hotel.n.01')))\n",
    "    except: \n",
    "        missing_terms.append(term)\n",
    "        #print(\"The term '{}' is not in WordNet \".format(term))\n",
    "\n",
    "wup_sorted_tuples=sorted(wup_tuples, key=lambda tup: tup[1], reverse=True)\n",
    "labels2 = ['Term', 'WuP similarity']\n",
    "\n",
    "df_wup = pd.DataFrame.from_records(wup_sorted_tuples, columns=labels2)\n",
    "\n",
    "print(df_wup[1:51])\n",
    "\n",
    "print(f'Number of terms missing from WordNet encountered: {len(missing_terms)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSrp9CxZBRi8"
   },
   "source": [
    "- Let's compare the first 50 targets found with the two methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHl3BKki_1B2"
   },
   "outputs": [],
   "source": [
    "set_wup=set([t[0] for t in wup_sorted_tuples[1:51]])\n",
    "set_w2v=set([t[0] for t in w2v_sorted_tuples[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6RU6MzOA3G_",
    "outputId": "7c5c5dda-ae7a-4e87-8ae4-3b8c57d1bbed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture',\n",
       " 'barrier',\n",
       " 'basement',\n",
       " 'block',\n",
       " 'bridge',\n",
       " 'building',\n",
       " 'castle',\n",
       " 'cellar',\n",
       " 'closet',\n",
       " 'courtyard',\n",
       " 'decoration',\n",
       " 'duomo',\n",
       " 'facility',\n",
       " 'fountain',\n",
       " 'foyer',\n",
       " 'frame',\n",
       " 'garage',\n",
       " 'knob',\n",
       " 'lavatory',\n",
       " 'layer',\n",
       " 'lobby',\n",
       " 'office',\n",
       " 'patio',\n",
       " 'rail',\n",
       " 'shelter',\n",
       " 'stadium',\n",
       " 'surface',\n",
       " 'terrace',\n",
       " 'theatre',\n",
       " 'toilet',\n",
       " 'tower',\n",
       " 'wall',\n",
       " 'window',\n",
       " 'works'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_wup-set_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ya7HhMuAA6i-",
    "outputId": "e3c7171d-29d1-4881-fe62-d147ebf65530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accommodation',\n",
       " 'airport',\n",
       " 'apartments',\n",
       " 'bar',\n",
       " 'bellmen',\n",
       " 'cabin',\n",
       " 'chambermaid',\n",
       " 'concierge',\n",
       " 'deluxe',\n",
       " 'doorman',\n",
       " 'downtown',\n",
       " 'elevator',\n",
       " 'guest',\n",
       " 'guests',\n",
       " 'honeymoon',\n",
       " 'hospitality',\n",
       " 'hotels',\n",
       " 'lodge',\n",
       " 'lounge',\n",
       " 'luxury',\n",
       " 'maid',\n",
       " 'mall',\n",
       " 'occupancy',\n",
       " 'plush',\n",
       " 'rental',\n",
       " 'residence',\n",
       " 'restaurants',\n",
       " 'rooms',\n",
       " 'salon',\n",
       " 'spa',\n",
       " 'suite',\n",
       " 'taxi',\n",
       " 'tourist',\n",
       " 'tourists'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_w2v-set_wup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rqx2rvRnhShc"
   },
   "source": [
    "#### Comments\n",
    "\n",
    "From the comparison between the targets found exclusively by each method I would say that the targets found by the w2v model are more appropriate as we have a lot of terms that represent things in a hotel that a customer may have an opinion about. For instance: accommodation, bar, bellmen, doorman, hospitality, lodge, lounge, rooms, suite, spa...\n",
    "\n",
    "We can also see that from all the candidates to be targets the wordnet model discards 1142 of them because they are not in its database, while the wv2 supermodel of GoogleNews discards only 313 of the candidates. This is a known problem with WordNet as it misses many of the less used and relatively new words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We find the aspects related to the target according to the Word2Vec model. We find the phrases semantically similar to the targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLXdSUIxW27L"
   },
   "outputs": [],
   "source": [
    "def aspects(target,candidates, thresh):\n",
    "  aspects=[]\n",
    "  for c in candidates:\n",
    "    similarity=wv.similarity(target,c)\n",
    "    if c!=target and similarity>thresh:\n",
    "      aspects.append((c,similarity))\n",
    "  return aspects\n",
    "\n",
    "targets=df_similarity['Term'].tolist()\n",
    "targets.append('hotel')\n",
    "\n",
    "target_aspects={target:aspects(target,targets,0.35) for target in targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sQ6Q4QVbTh0",
    "outputId": "395e5610-8413-462b-9392-03da61779b0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hotels', 0.77097285),\n",
       " ('motel', 0.66171205),\n",
       " ('restaurant', 0.57237756),\n",
       " ('inn', 0.55903065),\n",
       " ('apartment', 0.5006558),\n",
       " ('airport', 0.48113677),\n",
       " ('rooms', 0.47720072),\n",
       " ('hospitality', 0.4728384),\n",
       " ('spa', 0.47282827),\n",
       " ('luxury', 0.47001636),\n",
       " ('occupancy', 0.46986637),\n",
       " ('accommodation', 0.46953398),\n",
       " ('lodge', 0.4682071),\n",
       " ('room', 0.46567726),\n",
       " ('tourist', 0.46373928),\n",
       " ('penthouse', 0.4624656),\n",
       " ('apartments', 0.45567948),\n",
       " ('guests', 0.45522782),\n",
       " ('hostel', 0.44753048),\n",
       " ('bellmen', 0.44641432),\n",
       " ('concierge', 0.44381618),\n",
       " ('lounge', 0.43101066),\n",
       " ('palace', 0.42241666),\n",
       " ('doorman', 0.41629168),\n",
       " ('restaurants', 0.41617218),\n",
       " ('marina', 0.40823388),\n",
       " ('cafe', 0.4020607),\n",
       " ('mall', 0.3997244),\n",
       " ('pub', 0.3995665),\n",
       " ('taxi', 0.38674596),\n",
       " ('downtown', 0.3828734),\n",
       " ('house', 0.38227427),\n",
       " ('residence', 0.37999085),\n",
       " ('hospital', 0.37931976),\n",
       " ('chambermaid', 0.37897807),\n",
       " ('bathroom', 0.3781805),\n",
       " ('guest', 0.37624604),\n",
       " ('honeymoon', 0.3761602),\n",
       " ('bedroom', 0.37577185),\n",
       " ('deluxe', 0.37515998),\n",
       " ('balcony', 0.3738087),\n",
       " ('tourists', 0.37178215),\n",
       " ('rental', 0.36793822),\n",
       " ('elevator', 0.36737135),\n",
       " ('cabin', 0.366397),\n",
       " ('maid', 0.36549917),\n",
       " ('salon', 0.365072),\n",
       " ('suite', 0.36301348),\n",
       " ('plush', 0.36098066),\n",
       " ('bar', 0.36027604),\n",
       " ('breakfast', 0.3595047),\n",
       " ('cab', 0.3505972)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_aspects['hotel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epxV4HBpY8bg",
    "outputId": "0fd4a87c-74e6-4389-dcdc-66d8ddbb9b35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hotels', 0.4206994),\n",
       " ('motel', 0.45492327),\n",
       " ('inn', 0.4916499),\n",
       " ('apartment', 0.37224898),\n",
       " ('spa', 0.39078528),\n",
       " ('lounge', 0.38224435),\n",
       " ('doorman', 0.3871286),\n",
       " ('restaurants', 0.7722894),\n",
       " ('marina', 0.39246947),\n",
       " ('cafe', 0.6767455),\n",
       " ('mall', 0.44909427),\n",
       " ('pub', 0.5730096),\n",
       " ('taxi', 0.35405153),\n",
       " ('downtown', 0.40200517),\n",
       " ('salon', 0.51383865),\n",
       " ('bar', 0.5545204),\n",
       " ('breakfast', 0.42089343),\n",
       " ('nightlife', 0.41031972),\n",
       " ('waiter', 0.560682),\n",
       " ('eateries', 0.69405955),\n",
       " ('supermarket', 0.4991633),\n",
       " ('showroom', 0.37602308),\n",
       " ('catering', 0.42562118),\n",
       " ('boutique', 0.40765363),\n",
       " ('bartender', 0.5419379),\n",
       " ('barman', 0.3909236),\n",
       " ('dinner', 0.44607872),\n",
       " ('buffet', 0.5079515),\n",
       " ('waitress', 0.5417483),\n",
       " ('kitchen', 0.5017215),\n",
       " ('terrasse', 0.39377174),\n",
       " ('bakery', 0.59665316),\n",
       " ('shops', 0.39018017),\n",
       " ('shop', 0.48757964),\n",
       " ('pubs', 0.374289),\n",
       " ('plaza', 0.35097906),\n",
       " ('caf', 0.5124783),\n",
       " ('ambiance', 0.353152),\n",
       " ('trendy', 0.36814985),\n",
       " ('patio', 0.44196337),\n",
       " ('waitresses', 0.48575756),\n",
       " ('decor', 0.3542316),\n",
       " ('meal', 0.43459508),\n",
       " ('bars', 0.35479444),\n",
       " ('lunch', 0.4041293),\n",
       " ('patrons', 0.40093175),\n",
       " ('tapas', 0.5356922),\n",
       " ('grocery', 0.39141792),\n",
       " ('chain', 0.39005622),\n",
       " ('pizza', 0.5359172),\n",
       " ('seafood', 0.48550376),\n",
       " ('menu', 0.51966816),\n",
       " ('steak', 0.45262432),\n",
       " ('food', 0.42040867),\n",
       " ('supper', 0.35491297),\n",
       " ('homey', 0.35590103),\n",
       " ('salad', 0.41475308),\n",
       " ('pastries', 0.36644506),\n",
       " ('dishes', 0.4491334),\n",
       " ('sandwiches', 0.4372221),\n",
       " ('eat', 0.3578996),\n",
       " ('dish', 0.39575002),\n",
       " ('cooking', 0.37050992),\n",
       " ('meats', 0.35973015),\n",
       " ('hotel', 0.57237756)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_aspects['restaurant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEQYyyc7Di77",
    "outputId": "39ad4e3b-cab8-4234-81b9-90f2828504bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('motel', 0.6163505249553256),\n",
       " ('inn', 0.6575896538355771),\n",
       " ('apartment', 0.5611244887113571),\n",
       " ('spa', 0.3828926384449005),\n",
       " ('lounge', 0.4688999520407783),\n",
       " ('doorman', 0.40409061155821147),\n",
       " ('marina', 0.5491759093368755),\n",
       " ('cafe', 0.8089609724633834),\n",
       " ('mall', 0.5186647799085169),\n",
       " ('pub', 0.6982695109703961),\n",
       " ('taxi', 0.42702576518058777),\n",
       " ('downtown', 0.3885025829076767),\n",
       " ('salon', 0.590252657731374),\n",
       " ('bar', 0.6302013905609356),\n",
       " ('waiter', 0.4908673151543266),\n",
       " ('supermarket', 0.5495816498994828),\n",
       " ('showroom', 0.5409527184332119),\n",
       " ('boutique', 0.5196162885741183),\n",
       " ('bartender', 0.493191166056527),\n",
       " ('barman', 0.41768401695622337),\n",
       " ('buffet', 0.5480933960746317),\n",
       " ('waitress', 0.47087414264678956),\n",
       " ('kitchen', 0.6038019271457897),\n",
       " ('bakery', 0.614116055400748),\n",
       " ('shop', 0.5771231551965077),\n",
       " ('plaza', 0.3519601182026022),\n",
       " ('patio', 0.5959816873073578),\n",
       " ('decor', 0.5104491313298543),\n",
       " ('meal', 0.3506308724482854),\n",
       " ('bars', 0.4551749991046058),\n",
       " ('grocery', 0.511498433978934),\n",
       " ('pizza', 0.3929586112499237),\n",
       " ('seafood', 0.38560902433735983),\n",
       " ('steak', 0.35131216049194336),\n",
       " ('food', 0.36405048691309416),\n",
       " ('dish', 0.5103750079870224),\n",
       " ('hotel', 0.7236887812614441)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Wordnet_filter(target, thresh):\n",
    "  wup_tuples=[]\n",
    "  missing_terms=[]\n",
    "\n",
    "  for term,similarity in target_aspects[target]:\n",
    "    try:\n",
    "      term=term.strip().replace(' ', '_')\n",
    "      sense_term=wn.synset(term+'.n.01')\n",
    "      wup_similarity= sense_term.wup_similarity(wn.synset(target +'.n.01'))\n",
    "      if (wup_similarity+similarity)/2>thresh: #or simply wup_similarity > thresh\n",
    "        wup_tuples.append((term, (wup_similarity+similarity)/2)) #or (term, wup_similarity)\n",
    "    except:\n",
    "      missing_terms.append(term)\n",
    "  return wup_tuples\n",
    "\n",
    "Wordnet_filter('restaurant',0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crw0mLKchShd"
   },
   "source": [
    "#### Comments\n",
    "\n",
    "The aspects found for the targets are overall adequate. If we decrease the threshold we will find more candidates that are not really aspects of the selected target. \n",
    "\n",
    "For instance let's analyze the aspects found for the target 'restaurant': the noun phrases 'apartment', 'restaurants', 'marina', 'spa', 'mall', 'supermarket', 'taxi' and others maybe are related to the target but they are not really aspects of a restaurant. \n",
    "\n",
    "Using WordNet we can filter again the aspects found by our w2v model analyzing their (of one of their synset for simplicity) Wu and Palmer distance with the target and take only the candidates that have similarity above a desired threshold. We could also combine the two similarity distances calculated doing their arithmentic mean and compare it to the threshold.\n",
    "\n",
    "Using this method we are left with words like 'lounge, cafe, salon, bar, waiter, bartender, barman, waiter, waitress, kitchen, meal, pizza, steak, food, dish' that are aspects of a restaurant, but we also still have some words that are not aspects of restaurant.\n",
    "\n",
    "We have to be cautious using Wordnet because we have to consider different possible synset of the same word and also the fact that a lot of words may be missing from wordnet as we have seen in the previous exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9X2PXYnb-cNU"
   },
   "outputs": [],
   "source": [
    "'''If we are interested in finding the aspects that refer to the targets in each one of the reviews we can build the list \n",
    "of all the reviews and then store the noun phrases found in each one of the reviews in another list. \n",
    "Then we can adapt the procedure done above to the noun phrases in this list to find the aspects that refer to\n",
    "the targets in each review.'''\n",
    "\n",
    "#opinions=[word_tokenize(opinion.lower()) for opinion in hotel_opinions_data['review'].to_list()]\n",
    "#aspectos=[[get_np(phrase) for phrase in model_phrases[opinion] if get_np(phrase)!=''] for opinion in opinions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will see if the targets in the opinions differs between nationalities (e.g. if the reviewer is from UK or USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hdYCKqxhShd"
   },
   "outputs": [],
   "source": [
    "nationality_opinions={}\n",
    "nationalities=hotel_opinions_data['reviewer_nationality'].unique()\n",
    "for n in nationalities:\n",
    "  idx=hotel_opinions_data['reviewer_nationality']==n\n",
    "  nationality_opinions[n]=' '.join(hotel_opinions_data[idx]['review'].to_list()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-tLryqYm2LWf",
    "outputId": "90544595-6bc2-4498-c640-d671d326382d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "nationality_targets={}\n",
    "for n in nationality_opinions:\n",
    "  phrases=model_phrases[word_tokenize(nationality_opinions[n])]\n",
    "  targets=[get_np(candidate) for candidate in phrases]\n",
    "  targets=[s for s in targets if s!='']\n",
    "  nationality_targets[n]=set(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47W2J6AS4xK6",
    "outputId": "2a4d6fcd-ba08-44c0-df6f-58682f739519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of targets that are encountered only in one of the two nationality opinions:  1540\n"
     ]
    }
   ],
   "source": [
    "print('Number of targets that are encountered only in one of the two nationality opinions: ' , \n",
    "len(nationality_targets[' United Kingdom '].symmetric_difference(nationality_targets[' United States of America '])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnQ2QHKO5b8q",
    "outputId": "efc8562a-363e-42df-a756-aca973d425b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of targets encountered in both nationality opinions:  367\n"
     ]
    }
   ],
   "source": [
    "print('Number of targets encountered in both nationality opinions: ', \n",
    "len(nationality_targets[' United Kingdom '] & nationality_targets[' United States of America ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dTySrE56v90"
   },
   "source": [
    "- There are a lot of noun phrases that are exclusive of one of the two nationalities analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yp7HZ8A27Ja8",
    "outputId": "f7bf2cee-0d5f-4d15-f050-b4dd294af675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets exclusive of UK:  {'ect', 'student', 'badges', 'dinner', 'i_ll', 'majority', 'criticisms', 'definite', 'barcelona', 'description', 'pillowcase', 'busiest', 'difficulty', 'louder', 'straightens', 'sausage', 'travellers', 'paper', 'position', 'courtesy', 'theme', 'partners', 'system', 'client', 'scratches', 'choose', 'cot', 'grimy', 'heat', 'include', 'cut', 'dont', 'buzzing', 'eye', 'guess', 'checked', 'threadbare', 'cities', 'cheap', 'metropole', 'met', 'gras', 'look', 'rank', 'paintwork', 'considerate', 'relative', 'girlfriend', 'inbetween', 'mouth', 'pots', 'uniqueness', 'effort', 'exsperience', 'hadn_t', 'remind', 'fitness', 'milk', 'bonus', 'contact', 'strange', 'grenfell', 'hostel', 'nevermind', 'stand', 'cards', 'speed', 'speaker', 'woken', 'bowels', 'ni', 'corridor', 'shoulder', 'dodgy', 'apple', 'revamp', 'lazy', 'teenage', 'trendy', 'awesome', 'baths', 'days', 'vienna', 'answerphone', 'love', 'trades', 'music', 'sick', 'company', 'advise', 'verge', 'cash', 'heating', 'trvelodge', 'glass', 'speak', 'slice', 'hall', 'groups', 'explanation', 'centre', 'queue', 'hairdryer', 'eg', 'dusty', 'boat', 'couldnt', 'group', 'court', 'drinking', 'utilities', 'tiles', 'batersea', 'male', 'appointedone', 'peacefulness', 'itd', 'shirts', 'latino', 'bathrooms', 'department', 'opening', 'hugo', 'step', 'situation', 'cups', 'lavatory', 'closet', 'score', 'supervisor', 'connections', 'lie', 'departure', 'bedroom', 'charity', 'condensation', 'tattoos', 'thames', 'loud', 'crockery', 'karls', 'soundproof', 'bathrobe', 'gown', 'apology', 'curtains', 'suggest', 'stood', '10mins', 'kengsington', 'feature', 'loo', 'knows', 'spam', 'seat', 'hospitality', 'annoyed', 'beaches', 'heater', 'conplain', 'refund', 'delivery', 'mine', 'ade', 'issues', 'tasteless', 'finish', 'lumpy', 'broadway', 'resturant', 'result', 're', 'detail', 'points', 'z', 'computer', 'checkout', 'described', 'prosecco', 'lockers', 'creeky', 'fact', 'nuisance', 'shame', 'balcony', 'satisfactory', 'impatient', 'stock', 'bling', 'renovation', 'heaters', 'drivers', 'o2', 'earls', 'drains', 'surroundings', 'wont', 'browns', 'extracter', 'pass', 'enemy', 'accomodation', 'convey', 'construction', 'picky', 'bite', 'lodge', 'parasol', 't_think', 'command', 'evidence', 'communal', 'university', 'geyser', 'isnt', 'wind', 'mushroom', 'disturbed', 'show', 'disaster', 'length', 'midday', 'months', 'correct', 'mobility', 'fine', 'deposit', 'feels', 'brown', 'italy', 'reasons', 'whole', 'opinion', 'waste', 'cleaning', 'curtain', 'tables', 'edge', 'chaos', 'sleep', 'premises', 'gilmour', 'bottles', 'shelf', 'honest', 'warm', 'steps', 'temperature', 'arrival', 'purpose', 'item', 'smells', 'doorman', 'watch', 'action', 'awful', 'knives', 'flowers', 'relentless', 'attache', 'eurostar', 'grumbles', 'ambiance', 'mile', 'energy', 'attire', 'changes', 'degrees', 'pub', 'channel', 'plenty', 'burden', 'occupants', 'concerts', 'nat', 'boiler', 'ball', 'wouldnt', 'sensors', 'leisure', 'luke', 'didnt', 'filthy', 'jarring', 'safety', 'ventilation', 'waitress', 'euros100', 'junk', 'venue', 'con', 'plain', 'weekend', 'diet', 'ravioli', 'afraid', 'bag', 'wonderland', 'walls', 'anybody', 'longer', 'penis', 'travelidge', 'marmalade', 'cabin', 'mins', 'ground', 'december', 'moment', 'okay', 'escape', 'ferry', 'guarantees', 'couples', 'gym', 'spoons', 'straight', 'child', 'queen', 'closeness', 'batteries', 'beer', 'fianc', 'drawn', 'walkin', 'chino', 'england', 'levels', 'pizza', 'occurance', 'seafood', 'accommodation', 'daughter', 'drainage', 'platz', 'payment', 'bins', 'delay', 'tell', 'janel', 'shampoo', 'hung', 'blonde', 'complaint', 'mistake', 'kettle', 'litter', 'cable', 'layout', 'worldwide', 'i_didn', 'grubby', 'lg1', 'problem', 'accuse', 'overoll', 'surcharge', 'bathtub', 'investigate', 'peaceful', 'spoke', 'hang', 'royalty', 'box', 'cookie', 'cute', 'traveller', 'amongst', 'mattress', 'computers', 'cctv', 'fault', 'comments', 'doors', 'cleaner', 'unsure', 'apartments', 'poolside', 'orange', 'occupant', 'means', 'horrid', 'gentleman', 'refill', 'roof', 'inappropriate', 'juice', 'breakfasts', 'pushy', 'dealt', 'solve', 'managers', 'hooks', 'enjoy', 'lay', 'meant', 'confitbale', 'art', 'raise', 'blowing', 'ourselves', 'ambience', 'interact', 'cupboards', 'burning', 'meat', 'pricey', 'seconds', 'instructions', 'tap', 'blue', 'heard', 'delux', 'customers', 'stylish', 'trading', 'marked', 'contraption', 'herbal', 'inn', 'gower', 'bedrooms', 'estsblishment', 'teeth', 'list', 'dishes', 'sunday', 'june', 'remiss', 'rail', 'tiredness', 'trek', 'delt', 'cotton', 'christmas', 'lady', 'claim', 'pc', 'copy', 'toothbrush', 'elevator', 'staffs', 'fans', 'duty', 'tourist', 'restful', 'gig', 'mean', 'absurd', 'spend', 'ia', 'remote', 'privilege', 'covent', 'meal', 'sorry', 'albert', 'furnishings', 'disgrace', 'tissues', 'facility', 'rip', 'manoeuvre', 'hours', 'route', 'offs', 'holiday', 'friends', 'hyde', 'snacks', 'amend', 'round', 'extractor', 'basin', 'ajax', 'stirrers', 'trains', 'please', 'ware', 'thanks', 'roon', 'plaza', 'waiter', 'sent', 'iphone', 'credit', 'solo', 'restsurant', 'events', 'foam', 'th', 'useless', 'victor', 'charges', '10th', 'shopping', 'calls', 'images', 'communication', 'stairs', 'height', 'negatives', 'sse', 'f', 'flames', 'foldaway', 'toothpaste', 'mood', 'gristle', 'presume', 'don_t', 'represent', 'environment', 'lg', 'warmer', 'party', 'friendliest', 'frame', 'stains', 'policy', 'pensioner', 'spoilt', 'accor', 'penny', 'lifts', 'accommodate', 'quay', 'feather', 'traveler', 'beforehand', 'decent', 'saggy', 'shaken', 'come', 'sausages', 'spa', 'racetrack', 'mirrors', 'alternative', 'break', 'extras', 'wise', 'politest', 'process', 'gardens', 'matter', 'hairs', 'wembley', 'wake', 'nices', 'lunch', 'toddle', 'tall', 'trust', 'stadium', 'protection', 'brush', 'thank', 'dustmen', 'reluctant', 'makeover', 'biro', 'scent', 'reach', 'doumo', 'quirky', 'substandard', 'evident', 'help', 'fi', 'suit', 'works', 'executive', 'topped', 'inaccurate', 'plates', 'replacement', 'mayfair', 'fall', 'pokey', 'poster', 'moves', 'raw', 'hair', 'carpet', 'smile', 'ex', 'sellection', 'castle', 'pubs', 'edgeware', 'navigate', 'sundowner', 'impression', 'manners', 'vacuumed', 'approx', 'someone', 'port', 'wardrobe', 'products', 'max', 'david', 'matters', 'aperitivi', 'squeaky', 'inadequate', 'manage', 'overtime', 'noisy', 'hefty', 'conversation', 'looks', 'rain', 'lorry', 'birthday', 'device', 'fire', 'tidy', 'knock', 'creaky', 'maids', 'toiletries', 'online', 'highways', 'tbe', 'forth', 'scruffy', 'deco', 'closer', 'guard', 'wear', 'reason', 'mirror', 'end', 'nibbles', 'accounts', 'tissue', 'immaculate', 'headings', 'dome', 'delightful', 'needs', 'recognise', 'racist', 'royal', 'pic', 'bucket', 'steak', 'control', 'block', 'barrier', 'statement', 'cereals', 'sewage', 'stuck', 'ease', 'jacket', 'stench', 'worthy', 'wool', 'colleague', 'slippers', 'bulter', 'brother', '5th', 'joke', 'cider', 'web', 'gluten', 'dock', '10minutes', 'wood', 'courtyard', 'behaviour', 'services', 'chair', 'cant', 'mattresses', 'mind', 'cocktail', 'catering', 'attitude', 'expectation', 'ample', 'desperate', 'concierge', 'allways', 'rearrange', 'untidy', 'pins', 'fab', 'gift', 'blood', 'rd', 'ignore', 'ate', 'zone', 'cancer', 'trip', 'gel', 'starts', 'bill', 'smelt', 'slept', 'affect', 'smoke', 'visit', 'toilets', 'year', 'freshen', 'pillow', 'mail', 'thin', 'lack', 'shoulders', 'hope', 'regimental', 'hrs', 'walks', 'shortage', 'tonic', 'til', 'alittle', 'canary', 'toast', 'park', 'proves', 'packed', 'slid', 'swings', 'theatre', 'read', 'ones', 'driven', 'cooped', 'class', 'advantage', 'maneuver', 'match', 'somone', 'handy', 'passing', 'odd', 'brazil', 'worry', 'apologise', 'rambla', 'cheapest', 'letter', 'glasses', 'shut', 'transport', 'forks', 'minute', 'july', 'soap', 'improvement', 'wiliam', 'upstairs', 'cab', 'v', 'basement', 'tlc', 'bouncy', 'vat', 'screen', 'aren', 'drawback', 'return', 'appointment', 'fork', 'condition', 'excel', 'funky', 'hygiene', 'overhead', 'regent', 'id', 'damp', 'title', 'locate', 'world', 'stuff', 'representation', 'yellow', 'ideal', 'value', 'bin', 'benefit', 'sofa', 'course', 'seats', 'advance', 'fast', 'nightlife', 'paint', 'periods', 'attractions', 'yard', 'smiles', 'map', 'feminine', 'euston', 'digital', 'produce', 'torn', 'convention', 'color', 'bookings', 'sporadic', 'decide', 'isn_t', 'fountain', 'privacy', 'aircon', 'maid', 'cooked', 'lime', 'edgy', 'insufficient', 'meaning', 'oxford', 'sim', 'problems', 'hash', 'speakers', 'accident', 'movies', 'tag', 'renovations', 'tourists', 'sara', 'helpfull', 'bicuits', 'outlook', 'emirate', 'diy', 'team', 'lies', 'b', 'girl', 'banging', 'excuse', 'brownie', 'license', 'unit', 'account', 'springs', 'confirm', 'summer', 'function', 'understand', 'site', 'civilisation', 'ibis', 'part', 'dislike', 'self', 'light', 'lamps', 'socket', 'response', 'tobago', 'charger', 'scenic', 'pregnant', 'steam', 'avoid', 'macaroon', 'interaction', 'trips', 'helpfullness', 'story', 'duomo', 'incompetent', 'interior', 'reflect', 'hospital', 'awake', 'unfortunate', 'pot', 'wish', 'face', 'quicker', 'hastle', 'plug', 'language', 'alot', 'concern', 'ties', 'entertainment', 'thought', 'dreadful', 'theyll', 'touch', 'worn', 'persons', 'egg', 'monday', 'cookies', 'fois', 'n', 'arm', 'adequate', 'share', 'rush', 'something', 'trappings', 'trams', 'rogue', 'plannnig', 'internet', 'taps', 'extortionate', 'grumpy', 'probkem', 'others', 'corridors', 'facelift', 'receptions', 'wharf', 'sockets', 'tucked', 'chocolate', 'everyday', 'circus', 'fitting', 'wi', 'bowl', 'hazard', 'middle', 'rooftop', 'sound', 'cheaper', 'advisor', 'lift', 'shock', 'tour', 't_change', 'bathrobes', 'brand', 'crap', 'generator', 'supply', 'kit', 'travelodge', 'teabags', 'event', 'tub', 'singles', 'iron', 'string', 'write', 'interest', 'musty', 'keys', 'plate', 'showroom', 'robes', 'house', 'inability', 'grounds', 'staffhigh', 'foods', 'date', 'glad', 'flush', 'boxes', 'sin', 'years', 'complain', 'messy', 'bottle', 'attention', 'fair', 'feet', 'ill', 'missus', 'word', 'mess', 'ok', 'disrupt', 'receive', 'pre', 'oosterpark', 'disrespectful', 'tomatoes', 'midnight', 'pipes', 'hassle', 'faulty', 'stuffed', 'expense', 'sink', 'clipper', 'concrete', 'sell', 'image', 'briefcase', 'complimentary', 'bother', 'apartment', 'week', 'cutlery', 'heel', 'bits', 'requests', 'sky', 'jacuzzi', 'held', 'marshall', 'frames', 'minor', 'point', 'hanger', 'tube', 'whatsoever', 'courses', 'miles', 'range', 'i_don', 't', 'arena', 'kids', 'passionate', 'milan', 'pan', 'armchair', 'afternoon', 'adults', 'grout', 'downside', 'congratulations', 'dam', 'adjacent', 'stops', 'baby', 'heron', '18th', 'pm', 'arguments', 'surprise', 'spot', 'accent', 'blind', 'roomy', 'daughters', 'decore', 'sat', 'wooden', 'draw', 'blockage', 'website', 'ripped', 'beers', 'grotty', 'atrium', 'ziggo', 'vitoria', 'thetime', 'likeness', 'frayed', 'twin', 'tooth', 'drilling', 'gather', 'patch', 'noisey', 'plush', 'tight', 'kept', 'carpets', 'paste', 'coke', 'en', 'faults', 'sight', 'lead', 'bedside', 'sshhh', 'matilda', 'beauty', 'seem', 'dissappointment', 'ran', 'expectations', 'ormer', 'knife', 'reall', 'tastes', 'malaysian', 'costs', 'crowne', 'purposes', 'dry', 'head', 'closing', 'temperamental', 'security', 'individuality', 'stays', 'buzzy', 'treatments', 'heart', 'sewarage', 'westfield', 'bland', 'suitcases', 'cistern', 'rest', 'areas', 'payed', 'intercontinental', 'won', 'hardship', 'dull', 'meals', 'ha', 'minister', 'lock', 'fold', 'duvet', 'overflow', 'ask', 'cooking', 'e', 've', 'garage', 'email', 'alarm', 'drab', 'beans', 'brilliant', 'saw', 'dish', 'wedding', 'demand', 'rubbish', 'rant', 'entrance', 'cupboard', 'towards', 'premier', 'wine', 'wash', 'journey', 'body', 'cat', 'hazards', 'variety', 'background', 'sleepers', 'yeah', 'rang', 'fun', 'jammed', 'weren', 'tear', 'g', 'chip', 'tea', 'state', 'refreshments', 'card', 'pressure', 'inferior', 'luxury', 'amount', 'outcrops', 'start', 'asleep', 'difference', 'reset', 'powder', 'vodka', 'spread', 'deluxe', 'balloons', 'p', 'laid', 'whilst', 'features', 'checkin', 'belongings', 'doubletree', 'signs', 'found', 'country', 'favour', 'relation', 'pin', 'mp3', 'st', 'compact', 'sauna', 'compket', 'compair', 'hell', 'cleanness', 'parents', 'darkness', 'fit', 'shone', 'flights', 'towel', 'euros20', 'begin', 'forget', 'easyjet', 'history', 'promises', 'cater', 'cigarette', 'prices', 'l', 'brushes', 'incorrect', 'mould', 'urine', 'modernness', 'son', 'supplier', 'rebook', 'evenings', 'certificate', 'oasis', 'shabby', '15mins', 'ensuite', 'customer', 'mistakes', 'dozen', 'error', 'frustration', 'boyfriend', 'jmmmmm', 'cos', 'teela', 'downstairs', 'ramblas', 'pancras', 'refurbishment', 'base', 'doesn_t', 'displayed', 'kitchen', 'cleaners', 'junior', 'sleepless', 'winter', 'climb', 'cloud', 'feedback', 'refreshment', 'licence', 'receipt', 'quirkiness', 'king', 'drag', 'weeks', 'package', 'weather', 'warmth', 'yesi', 'prepaid', 'biscuits', 'reviewers', 'kensington', 'doubt', 'holes', 'existent', 'authourisation', 'parks', 'nye', 'marks', 'square', 'im', 'destination', 'compensation', 'comforts', 'noise', 'tatty', 'disliked', 'dream', 'bacon', 'fobbed', 'treat', 'flutes', 'members', 'sister', 'grade', 'excellant', 'tepid', 'clothes', 'saturday', 'cemetery', 'amsterdam', 'brick_wall', 'carpark'}\n"
     ]
    }
   ],
   "source": [
    "print('Targets exclusive of UK: ', nationality_targets[' United Kingdom '].difference(nationality_targets[' United States of America ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKgNADKw7JmB",
    "outputId": "cfa47b88-6145-4025-bfde-8759ac1e0bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets exclusive of USA:  {'slide', 'folks', 'direction', 'macro', 'separation', 'promenade', 'bellmen', 'collections', 'rent', 'statue', 'propose', 'cake', 'hip', 'marina', 'champs', 'beverages', 'transfer', 'month', 'movement', 'deserves', 'chose', 'selections', 'layer', 'croissants', 'buildings', 'center', 'sweet', 'quarter', 'travelers', 'bulbs', 'linens', 'globe', 'mentions', 'readp', 'vicinity', 'outlet', 'waterloo', 'dire', 'nord', 'avaikability', 'proffessional', 'brisk', 'postage', 'peasy', 'def', 'trouble', 'maps', 'suitcase', 'justify', 'tenders', 'boats', 'sticky', 'inches', 'files', 'ripoff', 'breathing', 'scale', 'seine', 'humor', 'bourne', 'subway', 'opera', 'poter', 'gotten', 'google', 'matt', 'tend', 'candies', 'relaxed', 'pompidou', 'mark', 'vegetarians', 'blankets', 'blocks', 'emma', 'sooo', 'novotel', 'cocktails', 'seal', 'europe', 'guide', 'aluminum', 'sides', 'gathering', 'flight', 'yummy', 'cane', 'offerings', 'honors', 'workers', 'tie', 'rouge', 'uber', 'sinks', 'ac', 'fluent', 'dust', 'canal', 'motorway', '7th', 'km', 'bartender', 'cumbersome', 'shade', 'quaint', 'ounce', 'gherkin', 'hole', 'plans', 'foul', 'vibe', 'level', 'fruits', 'books', 'excursions', 'fits', 'blow', 'flippers', 'movie', 'systems', 'public', 'ir', 'hike', 'official', 'tranquil', 'shard', 'shop', 'secure', 'venice', 'clock', 'accessibility', 'touches', 'advice', 'inch', 'bakery', 'electronics', 'descriptions', 'challenge', 'purchase', 'plentiful', 'honeymoon', 'trees', 'emmanuel', 'yogurt', 'spartan', 'ft', 'boutique', 'costvery', 'noon', 'trajan', 'discuss', 'sq', 'louvre', 'representatives', 'sense', 'blanket', 'umbrella', 'ham', 'minimalist', 'doorstep', 'button', 'maker', 'refrigerator', 'tickets', 'fruit', 'establishment', 'damon', 'moulin', 'leaks', 'buses', 'one', 'attend', 'adapters', 'palace', 'reality', 'assistance', 'stark', 'experiences', 'drawer', 'buckingham', 'foreigners', 'deck', 'ledge', 'tape', 'chairs', 'appropriate', 'imply', 'ick', 'buyer', 'pour', 'rambas', 'city_s', 'support', 'bikes', 'tapas', 'awkward', 'leaves', 'job', 'lit', 'handle', 'canopy', 'notification', 'expert', 'mislead', 'sub', 'neighbors', 'filter', 'elysee', 'harry', 'zarah', 'plane', 'westminster', 'tons', 'choices', 'mall', 'vent', 'centrum', 'dismissive', 'roman', 'skin', 'transportation', 'headroom', 'thru', 'doorways', 'cushion', 'strike', 'flore', 'overnight', 'compares', 'ministry', 'weigh', 'inconvenience', 'teen', 'lesser', 'laundry', 'bait', 'eiffel', 'stamp', 'trash', 'knew'}\n"
     ]
    }
   ],
   "source": [
    "print('Targets exclusive of USA: ', nationality_targets[' United States of America '].difference(nationality_targets[' United Kingdom ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Polarity detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Obtaining and preprocessing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We obtain 1000 tweets about #Ukranie with the tweepy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFP1fX5KhShe"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import API\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "CONSUMER_KEY = ###\n",
    "CONSUMER_SECRET = ###\n",
    "ACCESS_KEY = ###\n",
    "ACCESS_SECRET = ###\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "\n",
    "query = 'Ukranie'\n",
    "max_tweets = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucadXTYUd4J0"
   },
   "outputs": [],
   "source": [
    "searched_tweets = [status for status in tweepy.Cursor(api.search, q=query).items(max_tweets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3a5bU-uMixT",
    "outputId": "9d600392-116a-4a20-e66b-583da0bacb5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(_api=<tweepy.api.API object at 0x7faa9683c990>, _json={'created_at': 'Fri Apr 22 08:40:26 +0000 2022', 'id': 1517423066300698626, 'id_str': '1517423066300698626', 'text': '@scythesociety Deutschland könnte der Ukraine dafür benötigtes Material liefern z.B die eingelagerten Marder.\\nDa kö… https://t.co/wB1XXTcNpl', 'truncated': True, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'scythesociety', 'name': 'Xel', 'id': 126903118, 'id_str': '126903118', 'indices': [0, 14]}], 'urls': [{'url': 'https://t.co/wB1XXTcNpl', 'expanded_url': 'https://twitter.com/i/web/status/1517423066300698626', 'display_url': 'twitter.com/i/web/status/1…', 'indices': [117, 140]}]}, 'metadata': {'iso_language_code': 'de', 'result_type': 'recent'}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': 1517291344837988352, 'in_reply_to_status_id_str': '1517291344837988352', 'in_reply_to_user_id': 126903118, 'in_reply_to_user_id_str': '126903118', 'in_reply_to_screen_name': 'scythesociety', 'user': {'id': 1497978403215007744, 'id_str': '1497978403215007744', 'name': 'Timo Heinlein', 'screen_name': 'MagicTAC', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 16, 'listed_count': 0, 'created_at': 'Sun Feb 27 16:55:19 +0000 2022', 'favourites_count': 47, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 16, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'de'}, created_at=datetime.datetime(2022, 4, 22, 8, 40, 26), id=1517423066300698626, id_str='1517423066300698626', text='@scythesociety Deutschland könnte der Ukraine dafür benötigtes Material liefern z.B die eingelagerten Marder.\\nDa kö… https://t.co/wB1XXTcNpl', truncated=True, entities={'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'scythesociety', 'name': 'Xel', 'id': 126903118, 'id_str': '126903118', 'indices': [0, 14]}], 'urls': [{'url': 'https://t.co/wB1XXTcNpl', 'expanded_url': 'https://twitter.com/i/web/status/1517423066300698626', 'display_url': 'twitter.com/i/web/status/1…', 'indices': [117, 140]}]}, metadata={'iso_language_code': 'de', 'result_type': 'recent'}, source='Twitter Web App', source_url='https://mobile.twitter.com', in_reply_to_status_id=1517291344837988352, in_reply_to_status_id_str='1517291344837988352', in_reply_to_user_id=126903118, in_reply_to_user_id_str='126903118', in_reply_to_screen_name='scythesociety', author=User(_api=<tweepy.api.API object at 0x7faa9683c990>, _json={'id': 1497978403215007744, 'id_str': '1497978403215007744', 'name': 'Timo Heinlein', 'screen_name': 'MagicTAC', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 16, 'listed_count': 0, 'created_at': 'Sun Feb 27 16:55:19 +0000 2022', 'favourites_count': 47, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 16, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=1497978403215007744, id_str='1497978403215007744', name='Timo Heinlein', screen_name='MagicTAC', location='', description='', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=0, friends_count=16, listed_count=0, created_at=datetime.datetime(2022, 2, 27, 16, 55, 19), favourites_count=47, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=16, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), user=User(_api=<tweepy.api.API object at 0x7faa9683c990>, _json={'id': 1497978403215007744, 'id_str': '1497978403215007744', 'name': 'Timo Heinlein', 'screen_name': 'MagicTAC', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 16, 'listed_count': 0, 'created_at': 'Sun Feb 27 16:55:19 +0000 2022', 'favourites_count': 47, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 16, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=1497978403215007744, id_str='1497978403215007744', name='Timo Heinlein', screen_name='MagicTAC', location='', description='', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=0, friends_count=16, listed_count=0, created_at=datetime.datetime(2022, 2, 27, 16, 55, 19), favourites_count=47, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=16, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1510921030046474245/RelQYbfh_normal.jpg', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='de')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searched_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pza_vt7xEddr"
   },
   "outputs": [],
   "source": [
    "tweets_text_list=[]\n",
    "for tweet in searched_tweets:\n",
    "  tweets_text_list.append(tweet._json['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fz1jt5b5eUod"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('tweets_text_list.txt', 'w') as f:\n",
    "    f.write(json.dumps(tweets_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOKKeoIsfEVu"
   },
   "outputs": [],
   "source": [
    "tweets_path='/content/drive/MyDrive/Colab Notebooks/NLP/PRA2/tweets_text_list.txt'\n",
    "\n",
    "with open(tweets_path, 'r') as f:\n",
    "    tweets_text_list = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "ir4tm_gWFn-l",
    "outputId": "b1037737-425a-4051-fee5-2125e13e364d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'@TurkishNews7 why greece not giving their s300 russian air defence systems? they send nothing to Ukranie... greece… https://t.co/Fr2VvJMwin'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_text_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filtering out strange characters, emojis, urls and unifying the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0coHB0XEhShf"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPdxGINGhShf"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text = emoji_pattern.sub(r'',text)\n",
    "  text = re.sub(r'(\\s)http\\S+','', text)\n",
    "  text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "  text = re.sub(r'[#@]','', text)\n",
    "  return text\n",
    "\n",
    "clean_tweets = [clean_text(sentence) for sentence in tweets_text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbRp_g7TzV0_",
    "outputId": "730f945a-4747-4c96-b5ac-ea8262200688"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Lisa40393817  lesiavasylenko 100 donablo to Ukranie ppls under war situation Banksy style 3d aretworks porweder by ',\n",
       " ' oldmordim 100  donable to Ukranie ppls under war situation  under Bansky style  3d artworks  NFTsaints powered by ',\n",
       " 'More of 100 resisters follow this account  Anti Biden  anti Ukranie  Maybe you got confused because her Twitter han ',\n",
       " ' denvergrl303  nathanjbridges  tariqnasheed  WithUcranie under Banksy style 3D ccryptoart 100  donable to Ukranie p ',\n",
       " 'RT  Comandante Sur   Sanchez el  socialista  amigo que le regala armas al criminal se  ZelenskyWarCriminal  la  Ukranie que ha ilegalizado ',\n",
       " ' MahmouSewar 100  donable to Ukranie ppls under war situation',\n",
       " '                                                                                          WeSupportMEK ',\n",
       " ' Vick top55  carlesenric  EmbajadaRusa  KremlinRussia C Hope not  They are spanish  nato  ships  And that means tot ',\n",
       " ' elonmusk Going to ukranie',\n",
       " ' EmiliaKaminska  OnetWiadomosci zobacz material o wojnie na Ukranie  https   t co 4vsMDDeVrd   Obszerny materia   g ',\n",
       " ' Alerta News   NATO  UN  antonioguterres  IntlCrimCourt  KarimKhanQC   Ukranie',\n",
       " 'New post  Ukranie Krieg  Deutschland bereitet Ringtausch f r Waffenlieferungen vor  has been published on ',\n",
       " 'Volodymyr Oleksandrovytch Zelensky Allah irhem lwalidine n gocie avec Poutine rah les occidentaux te poussent   fai ',\n",
       " '           GW                       Twitter                                                                       ',\n",
       " 'RT  ALJEEZW   ZelenskyyUa  POTUS  ZelenskyyUa   UKRANIE',\n",
       " ' ZelenskyyUa  POTUS  ZelenskyyUa   UKRANIE',\n",
       " ' heiseonline    zahlen Sie damit Putin aus  damit er endlich aus der Ukranie verschwindet    ',\n",
       " ' Alerta News  Con la solidaridad y compromiso   en S nchez se traduce mentiras y m s mentiras   seguro que Zelensky ',\n",
       " ' captain kimi 100  donable to Ukranie ppls under war situation  1 1  4 10  working on   FND   NFTsaints powered by ',\n",
       " ' Escampiquipugui  SantPons  Mercede35604584 Sisi  16000 morts violacions a nadons davant dels seus pares  glorifica ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pp74LhCuv2p5",
    "outputId": "9a288253-e411-428f-834a-671a480c1745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Lisa40393817 @lesiavasylenko 100%donablo to Ukranie ppls under war situation\\nBanksy style 3d aretworks porweder by… https://t.co/OwH7JzQm2g',\n",
       " '@oldmordim 100% donable to Ukranie ppls under war situation. under Bansky style, 3d artworks #NFTsaints powered by… https://t.co/lk8vErRXud',\n",
       " 'More of 100 resisters follow this account! Anti Biden, anti Ukranie! Maybe you got confused because her Twitter han… https://t.co/7W5ng6lLyR',\n",
       " '@denvergrl303 @nathanjbridges @tariqnasheed #WithUcranie under Banksy style 3D ccryptoart 100% donable to Ukranie p… https://t.co/uSf6kJxEw4',\n",
       " 'RT @Comandante_Sur: #Sanchez el \"socialista\" amigo que le regala armas al criminal se #ZelenskyWarCriminal, la #Ukranie que ha ilegalizado…',\n",
       " '@MahmouSewar 100% donable to Ukranie ppls under war situation https://t.co/h5GFkWd2iQ',\n",
       " '🌐 مهم\\u200cترین اخبار ایران و جهان در ۶۰ ثانیه\\n🔸️۵شنبه اول اردیبهشت \\u200c۱۴۰۱\\n🔹️۲۱ آوریل ۲۰۲۲\\n#خبر۶۰\\n#WeSupportMEK… https://t.co/rpGXaFUAWm',\n",
       " '@Vick_top55 @carlesenric @EmbajadaRusa @KremlinRussia_C Hope not. They are spanish (nato) ships. And that means tot… https://t.co/eyVRd4HazH',\n",
       " '@elonmusk Going to ukranie',\n",
       " '@EmiliaKaminska @OnetWiadomosci zobacz material o wojnie na Ukranie (https://t.co/4vsMDDeVrd). Obszerny materiał, g… https://t.co/Tj5bLWB4pB',\n",
       " '@Alerta_News_ @NATO @UN @antonioguterres @IntlCrimCourt @KarimKhanQC  #Ukranie',\n",
       " 'New post (Ukranie-Krieg: Deutschland bereitet Ringtausch für Waffenlieferungen vor) has been published on… https://t.co/ZBxyKzlMz7',\n",
       " 'Volodymyr Oleksandrovytch Zelensky Allah irhem lwalidine négocie avec Poutine rah les occidentaux te poussent à fai… https://t.co/sUJJfVFCW5',\n",
       " 'おはようございます😃\\n\\nGW前の最後の金曜日です\\n\\nイーロンマスクさん\\n\\nTwitterを買収？\\n\\nなんかよう分からんけど\\n\\n自分は自分の道を進むだけですね\\n\\n今日も一日穏やかに❗️\\n\\n#朝活\\n#プログラミング\\n#デジタルノマド… https://t.co/hwjX92e3rW',\n",
       " 'RT @ALJEEZW: @ZelenskyyUa @POTUS @ZelenskyyUa \\n#UKRANIE https://t.co/K6PEw0flwU',\n",
       " '@ZelenskyyUa @POTUS @ZelenskyyUa \\n#UKRANIE https://t.co/K6PEw0flwU',\n",
       " '@heiseonline ...zahlen Sie damit Putin aus, damit er endlich aus der Ukranie verschwindet....',\n",
       " '@Alerta_News_ Con la solidaridad y compromiso ( en Sánchez se traduce mentiras y más mentiras), seguro que Zelensky… https://t.co/LtDOLAkEeM',\n",
       " '@captain_kimi 100% donable to Ukranie ppls under war situation \\n1/1 \\n4/10 (working on)\\n#FND \\n#NFTsaints powered by… https://t.co/JWFPQlYfT5',\n",
       " '@Escampiquipugui @SantPons @Mercede35604584 Sisi, 16000 morts violacions a nadons davant dels seus pares, glorifica… https://t.co/eWm7uH2P0L']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_text_list[30:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZsNZSfShShf"
   },
   "source": [
    "## 2.2. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the dictionary of opinion words (AFINN-111) we get the polarity of each tweet as the mean of the opinion words of the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ip5-mKCl8WmL"
   },
   "source": [
    "I created the sentword dictionary with all the opinion words in AFINN as keys and their polarity value as values. \n",
    "\n",
    "The function mean_opinions takes as argument a text and finds all the words in AFINN that are present in our text, sums the polarity value of these words and then divides this value by how many words we encountered. With this procedure we obtain the mean of the polarity values of the opinion words in the input text.\n",
    "\n",
    "tweets_polarity is the list built by applying the mean_opinions function on every tweet in the list of tweets that we have preprocessed in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIA7n1umhShg",
    "outputId": "3b9bbe52-7fc8-4fcf-84e2-3fdc0eadb4af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.0, 0, -0.4, -3.0, -4.0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AFINN_path='/content/drive/MyDrive/Colab Notebooks/NLP/PRA2/data/AFINN-111.txt'\n",
    "\n",
    "sentword = {}\n",
    "\n",
    "with open(AFINN_path, 'r') as snf:\n",
    "    senlines = snf.readlines()\n",
    "    for sl in senlines:\n",
    "        sl = sl.strip().split('\\t')\n",
    "        sentword[sl[0]] = int(sl[1])\n",
    "\n",
    "def mean_opinions(text):\n",
    "    opinions_sum=0\n",
    "    count=0\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    for t in tokens:\n",
    "        if re.match(\"^[a-z]+.*\",t):\n",
    "            if t in sentword:\n",
    "                opinions_sum+=sentword[t]\n",
    "                count+=1\n",
    "    if count==0:\n",
    "        return 0\n",
    "    mean=opinions_sum/count\n",
    "    return mean\n",
    "\n",
    "tweets_polarity=[mean_opinions(tweet) for tweet in clean_tweets]\n",
    "tweets_polarity[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The emoji-polarity file contains a document similar to AFINN-111 but for emojis. We will use it to get the polarity of the tweets containing emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8Uik15C9hShg",
    "outputId": "5cd1b8c1-6a67-4ce1-acb4-3b6b90340b3d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'😠'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import codecs\n",
    "emoji_pol_path='/content/drive/MyDrive/Colab Notebooks/NLP/PRA2/data/emoji-polarity.txt'\n",
    "\n",
    "data = json.load(codecs.open(emoji_pol_path, 'r', 'utf-8-sig'))\n",
    "data[\"emojis\"][1]['emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_494aD5tn_ic"
   },
   "outputs": [],
   "source": [
    "emojis_polarity={data['emojis'][i]['emoji']:data['emojis'][i]['polarity'] for i in range(len(data['emojis']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHePha1rhShg"
   },
   "outputs": [],
   "source": [
    "def mean_emojis(text):\n",
    "    emojis_list=[]\n",
    "    opinions_sum=0\n",
    "    count=0\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    for t in tokens:\n",
    "      if re.match(\"^[a-z]+.*\",t):\n",
    "            if t in sentword:\n",
    "                opinions_sum+=sentword[t]\n",
    "                count+=1\n",
    "      if t in emojis_polarity:\n",
    "        emojis_list.append(t)\n",
    "        opinions_sum+=emojis_polarity[t]\n",
    "        count+=1\n",
    "    if count==0:\n",
    "        return 0, emojis_list\n",
    "    mean=opinions_sum/count\n",
    "    return mean, emojis_list #i made it return also the list of the emojis to check if it works properly\n",
    "\n",
    "tweets_polarity_emojis=[mean_emojis(tweet)[0] for tweet in tweets_text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30uuwKr0q5Sr",
    "outputId": "b54c3c27-b93c-46a9-b8d2-f2dc455f471e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41 tweets that have changed their polarity considering also the emojis\n",
      "Of these tweets, the mean value of the difference in polarity is: 0.9186991869918698\n",
      "The mean over all the tweets is 0.038992408557625945\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "difference=np.array(tweets_polarity_emojis)-np.array(tweets_polarity)\n",
    "\n",
    "print(f'There are {np.count_nonzero(difference)} tweets that have changed their polarity considering also the emojis')\n",
    "print(f'Of these tweets, the mean value of the difference in polarity is: {sum(difference)/np.count_nonzero(difference)}')\n",
    "print(f'The mean over all the tweets is {sum(difference)/len(difference)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5UjQVE1tdF6"
   },
   "source": [
    "#### Comments:\n",
    "\n",
    "Considering the emojis, the polarity of the tweets increases by slightly less than 1 point.\n",
    "It must be considered that we have encountered emojis (present in our dictionary) just in 41 tweets of the 1000 searched, so it may be not really significative, as the mean over all the tweets suggest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYet4w0phShh"
   },
   "source": [
    "# 3. Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oVg3wQQ2hShh",
    "outputId": "ef66c503-ae39-4b08-d36a-2bcdc8ae7a9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d8e287b9-8322-435a-961c-744e37d4b5e2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>reviewer_nationality</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l ascenseur No Positive</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Having to log in each day with a new login an...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the TV is crazy the hotel host a lot of natio...</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No complaints  Excellent location very helpfu...</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We booked an executive room with super king b...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8e287b9-8322-435a-961c-744e37d4b5e2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d8e287b9-8322-435a-961c-744e37d4b5e2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d8e287b9-8322-435a-961c-744e37d4b5e2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review reviewer_nationality  \\\n",
       "0                            l ascenseur No Positive             Lebanon    \n",
       "1   Having to log in each day with a new login an...           Australia    \n",
       "2   the TV is crazy the hotel host a lot of natio...               Qatar    \n",
       "3   No complaints  Excellent location very helpfu...             Ireland    \n",
       "4   We booked an executive room with super king b...      United Kingdom    \n",
       "\n",
       "  sentiment  \n",
       "0      good  \n",
       "1      good  \n",
       "2      good  \n",
       "3      good  \n",
       "4      good  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_opinions_data = pd.read_csv(hotel_opinions_path) \n",
    "\n",
    "hotel_opinions_data[\"sentiment\"] = hotel_opinions_data[\"Reviewer_Score\"].apply(lambda x: \"bad\" if x < 5 else \"good\")\n",
    "\n",
    "hotel_opinions_data = hotel_opinions_data[[\"review\",\"reviewer_nationality\", \"sentiment\"]]\n",
    "hotel_opinions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bne5cSS4Dhxl",
    "outputId": "4b7bec88-56aa-4de0-8a03-4d02e90915bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_opinions_data.isnull().sum().sum() #there are no NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsFuzLMpT5tw"
   },
   "source": [
    "The reviews are already stripped of punctuation so there is no need to do it in preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "1ZZ7JN3Wv1Hp",
    "outputId": "dd865110-7f14-4140-dd51-59f3c4dd07c0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' Evelein with short blonde hair Sana thin with short black hair at front desk are rude no social skills ill mannered discourteous seems like they don t like the guests asking them questions like where the train station is or how to go to tourist places etc In addition to that the chambermaid does not replenish the soap cosmetic vanity set cotton buds cotton pads emery board dental set and the face towel We have to ring the 2424 number to ask for these basic standard supplies It would be quite helpful if the staff personnel specially the front desk reception are fully well trained to receive incoming guests in a pleasant warm and welcoming manner They should have the utmost politeness and patience and also professionalism in dealing with all kinds of queries that the guest may have specially for tourists which is also our first time to visit in Amsterdam I hope the management takes this into serious account and take important note on this matter Good day and thank you   Hotel itself is nice but the front desk staffs personnel are TERRIBLE to say the least '"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I look at some opinions to see if the labeling good/bad is done right\n",
    "hotel_opinions_data[hotel_opinions_data['sentiment']=='bad']['review'].iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We vectorize the opinions with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzVqiYj9hShh",
    "outputId": "038985db-0914-48d6-e6ac-140d517d5f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on the test set is: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X=hotel_opinions_data['review'].values\n",
    "y=hotel_opinions_data['sentiment'].values\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf.A, y, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "# Let's see how the model performs on the test set\n",
    "score = accuracy_score(y_test, pred)\n",
    "print('The accuracy score on the test set is: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSN7r6MyhJq5",
    "outputId": "df212a20-5175-46d4-c252-9f1434fdeed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model classifies the review \" The sauna is a joke only 70C no changing rooms There were hairs on my bed and they weren t mine Im the bathroom the front part of the counter had fallen off No free wifi  nice to be on the waterfront\" as ['bad']\n"
     ]
    }
   ],
   "source": [
    "print(f'The model classifies the review \"{X[917]}\" as {lr.predict(X_tfidf[917])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9dJxls-UQZF",
    "outputId": "b586b31c-06fc-45f3-afff-c03b5dc471cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.81      0.54      0.65        72\n",
      "        good       0.78      0.93      0.85       128\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.80      0.74      0.75       200\n",
      "weighted avg       0.79      0.79      0.78       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cr = metrics.classification_report(y_test, pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5DTxFNBhShi"
   },
   "source": [
    "# 4. Evaluation and comparison of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try with others models or other preprocessing steps to try to improve the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUKlVuuthShi",
    "outputId": "4e22d1e1-e68e-4628-f3f8-016f30ad3b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def get_wn_pos(pos):\n",
    "    if re.match(r'^N',pos):\n",
    "        wn_pos = 'n'\n",
    "    elif re.match(r'^V',pos):\n",
    "        wn_pos = 'v'\n",
    "    else:\n",
    "        wn_pos = 'n' \n",
    "    return wn_pos\n",
    "\n",
    "def wnlemmatize(t):\n",
    "    lemma = t\n",
    "    lem = WordNetLemmatizer()\n",
    "    postag = nltk.pos_tag([t])\n",
    "    lemma = lem.lemmatize(t,get_wn_pos(postag[0][1]))\n",
    "    return lemma\n",
    "  \n",
    "\n",
    "lem=WordNetLemmatizer()\n",
    "reviews_tokenized=[word_tokenize(review) for review in X]\n",
    "reviews_lemmatized=[[wnlemmatize(token) for token in review] for review in reviews_tokenized]\n",
    "X_lemmatized=[' '.join(review) for review in reviews_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvUW9qs2OLxZ"
   },
   "outputs": [],
   "source": [
    "#cells below to see if it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flaHJ-jyJBuY"
   },
   "outputs": [],
   "source": [
    "diff_indexes=[i for i in range(len(reviews_tokenized[1])) if reviews_tokenized[1][i]!=reviews_lemmatized[1][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uge9EwyIMUS5",
    "outputId": "8ecc5066-b064-48c7-9f04-de367f2a4413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['was',\n",
       " 'mins',\n",
       " 'was',\n",
       " 'was',\n",
       " 'sparkling',\n",
       " 'bottled',\n",
       " 'provided',\n",
       " 'replenished']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reviews_tokenized[1][i] for i in diff_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yfx57yRoMcNH",
    "outputId": "bc40069a-9d03-4d13-d294-7d0d0ab07768"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be', 'min', 'be', 'be', 'sparkle', 'bottle', 'provide', 'replenish']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reviews_lemmatized[1][i] for i in diff_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EI9N0hpXMTVQ"
   },
   "outputs": [],
   "source": [
    "#filter out the stopwords\n",
    "tfidf_vectorizer_nostw = TfidfVectorizer(stop_words='english', lowercase=False)\n",
    "X_tfidf_2 = tfidf_vectorizer_nostw.fit_transform(X_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUt60PZlPer-",
    "outputId": "3a95f7d3-8366-4a7a-a355-4358adc5b1d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on the test set is: 0.81\n"
     ]
    }
   ],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(\n",
    "    X_tfidf_2.A, y, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_2, y_train_2)\n",
    "\n",
    "pred2 = lr2.predict(X_test_2)\n",
    "# Let's see how the model performs on the test set\n",
    "score2 = accuracy_score(y_test_2, pred2)\n",
    "print('The accuracy score on the test set is: {}'.format(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrOgpf0fUe5V",
    "outputId": "87caf3c0-6b41-4f3f-8fb9-fdcbe2f7c89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with lemmatization and without stopwords:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.89      0.54      0.67        72\n",
      "        good       0.79      0.96      0.87       128\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.84      0.75      0.77       200\n",
      "weighted avg       0.82      0.81      0.80       200\n",
      "\n",
      "\n",
      "Logistic regression with no preprocessing:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.81      0.54      0.65        72\n",
      "        good       0.78      0.93      0.85       128\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.80      0.74      0.75       200\n",
      "weighted avg       0.79      0.79      0.78       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr2 = metrics.classification_report(y_test_2, pred2)\n",
    "print('Logistic regression with lemmatization and without stopwords:')\n",
    "print(cr2)\n",
    "print('')\n",
    "print('Logistic regression with no preprocessing:')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s58p0VtkQ0F9"
   },
   "source": [
    "All metrics improved slightly (~ +0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9TpXbQtTxiR",
    "outputId": "40c03c24-2bf7-4cf6-f1cf-4f19b4607b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on the test set is: 0.825\n",
      "\n",
      "LinearSVC without lemmatization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.79      0.69      0.74        72\n",
      "        good       0.84      0.90      0.87       128\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.82      0.80      0.80       200\n",
      "weighted avg       0.82      0.82      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier = LinearSVC()\n",
    "\n",
    "svm_model = classifier.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "score3 = accuracy_score(y_test, y_pred)\n",
    "print('The accuracy score on the test set is: {}'.format(score3))\n",
    "cr3 = metrics.classification_report(y_test, y_pred)\n",
    "print('')\n",
    "print('LinearSVC without lemmatization:')\n",
    "print(cr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ID_sJzlWxPj",
    "outputId": "138e9169-4482-465a-ea0e-4148dcf0e40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on the test set is: 0.81\n",
      "\n",
      "LinearSVC with lemmatization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.77      0.68      0.72        72\n",
      "        good       0.83      0.88      0.86       128\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.80      0.78      0.79       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = LinearSVC()\n",
    "\n",
    "svm_model = classifier.fit(X=X_train_2, y=y_train_2)\n",
    "\n",
    "y_pred_2 = svm_model.predict(X_test_2)\n",
    "score4 = accuracy_score(y_test_2, y_pred_2)\n",
    "print('The accuracy score on the test set is: {}'.format(score4))\n",
    "cr4 = metrics.classification_report(y_test_2, y_pred_2)\n",
    "print('')\n",
    "print('LinearSVC with lemmatization:')\n",
    "print(cr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8H6IZcgvXEGR",
    "outputId": "178550e1-8038-4b25-bc98-e8bfbbac08ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.60      0.44      0.51        72\n",
      "        good       0.73      0.84      0.78       128\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.67      0.64      0.65       200\n",
      "weighted avg       0.68      0.69      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "rf_model = classifier.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred_5 = rf_model.predict(X_test)\n",
    "\n",
    "cr5 = metrics.classification_report(y_test, y_pred_5)\n",
    "print('RandomForest Classifier:')\n",
    "print(cr5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iDrHbBBaSQ1"
   },
   "source": [
    "We obtain the best performance using the LinearSVC model without lemmatizing the input. So I would say that good results depend more on the choice of the right model than on the preprocessing steps."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PRA2_LorenzoVenieri.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
